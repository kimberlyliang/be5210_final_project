{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQb8UNexzK6U"
      },
      "source": [
        "# BE 521: Final Project Part 1\n",
        "Spring 2025\n",
        "\n",
        "Adapted by Kevin Xie\n",
        "\n",
        "Updated by Zhongchuan Xu\n",
        "\n",
        "32 Points\n",
        "\n",
        "Objective: Predict finger movements from ECoG Recordings\n",
        "\n",
        "Due: April 10th\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUZMM3sHzR_P"
      },
      "source": [
        "# Project Overview\n",
        "\n",
        "This final project involves predicting finger flexion using intracranial EEG (ECoG) in three human subjects. The data and problem framing come from the 4th BCI Competition (Miller et al. 2008). For the details of the problem, experimental protocol, data, and evaluation, please see the original 4th BCI Competition documentation (included as separate document). The remainder of the current document details your deliverables for part 1 of the project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ehuowkc1TVO"
      },
      "source": [
        "## Important Deadlines\n",
        "* Final Project Part 1 (Canvas)\n",
        " * Due: April 10th\n",
        " * 32 Points\n",
        "* Team Registration\n",
        " * Due: April 10th\n",
        " * 5 Points\n",
        "* Team Responsibilities (Canvas)\n",
        " * Due: April 14th\n",
        " * 3 Point\n",
        "* Checkpoint 1, r > 0.33\n",
        " * Due: April 17th\n",
        " * 20 Points\n",
        "* Checkpoint 2, r > 0.45\n",
        " * Due: April 24th\n",
        " * 15 Points\n",
        "* End of competition, submit algorithm (Canvas):\n",
        " * Due: April 25th\n",
        " * 15 Points\n",
        "* Final Report\n",
        " * Due: April 27th\n",
        " * 60 Points\n",
        "* Competition results (Final class session)\n",
        " * On: April 30th\n",
        "\n",
        "The grading is structured so that going the extra mile is definitely rewarded. We want you to show what you've learned this semester, and to have some fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhDgvv4T1X4b"
      },
      "source": [
        "## Writing Your Code\n",
        "To get started with the final project we have provided a a series of method stubs for you to fill out. Your job for part 1 of the final project is to build a prediction pipeline that takes in the ECoG and dataglove finger angle recordings (serving as the data and labels respectively), then uses machine learning methods to generate predicted finger angles from the ECoG signals. The functions you will develop in this assignment are as follows:\n",
        "* `get_windowed_feats` This function will take in raw ECoG data, and use the 2 following helper functions to filter the data, calculate sliding-window features.\n",
        " * `filter_data` This function will apply a filter to the raw data and return cleaned data\n",
        " * `get_features` This function will take in a window of cleaned data and return a vector of features for that window\n",
        "* `create_R_matrix` This function will take in a feature matrix and return a response matrix as an adaptation of the optimal linear decoder method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u5g0qVr2C2M"
      },
      "source": [
        "## Optimal Linear Decoder\n",
        "You will use a modified version of the **optimal linear decoder** method as described in Warland et al., 1997. We will recapitulate the method in this section, but consult the paper for more details. Our ultimate goal is to predict the angle of each finger as it moves over time using data recorded from the ECoG channels.\n",
        "\n",
        "The position data is captured for 300 seconds, which you will split up into $M$ total time bins, and the number of ECoG channels, $\\nu$, is 61, 46, and 64 for subject 1, 2, and 3 respectively.\n",
        "\n",
        "The paradigm we adapt here tries to predict finger angle at a given time window using ECoG features calculated over the preceding $N$ time windows, using\n",
        "the following steps:\n",
        "\n",
        "First, $p$ features will be calculated across all $\\nu$ ECoG channels over $M$ total time windows to get a feature matrix of shape $\\bigl(M, (\\nu \\times p)\\bigr)$\n",
        "\n",
        "Then, following the approach that Warland et al., 1997 takes, we will construct a row vector corresponding to each time bin, that contains features for all the ECoG channels over the preceding *N* time bins (in the paper, spike counts are their features and they index neurons instead of ECoG channels). Thus, there will be a good amount of redundancy between row vectors of adjacent time bins, but that is okay.\n",
        "\n",
        "Let $r^{c,\\phi}_t$ be the value of the feature in window $t \\in \\{1,2,\\dots,M\\}$, channel $c\\in\\{1,2,\\dots,\\nu\\}$ and with feature $\\phi\\in\\{1,2,\\dots,p\\}$. Let the response matrix $R \\in \\mathbb{R}^{M \\times (1+N \\cdot p \\cdot \\nu )}$ be defined as:\n",
        "\n",
        "$$R = \\begin{bmatrix}\n",
        "\\mathbf{1} & r^{(1,1)}_1 & r^{(1,1)}_1 & \\cdots & r^{(1,1)}_1 & r^{(1,1)}_1 & r^{(1,2)}_1 & \\cdots & r^{(1,2)}_1 & \\cdots & r^{(\\nu,p)}_1 & \\cdots & r^{(\\nu,p)}_1\\\\\n",
        "\\mathbf{1} & r^{(1,1)}_1 & r^{(1,1)}_1 & \\cdots & r^{(1,1)}_1 & r^{(1,1)}_2 & r^{(1,2)}_1 & \\cdots & r^{(1,2)}_2 & \\cdots & r^{(\\nu,p)}_1 & \\cdots & r^{(\\nu,p)}_2\\\\\n",
        "\\mathbf{1} & r^{(1,1)}_1 & r^{(1,1)}_1 & \\cdots & r^{(1,1)}_2 & r^{(1,1)}_3 & r^{(1,2)}_1 & \\cdots & r^{(1,2)}_3 & \\cdots & r^{(\\nu,p)}_1 & \\cdots & r^{(\\nu,p)}_3\\\\\n",
        "\\vdots   & \\vdots     & \\vdots     & \\ddots & \\vdots     & \\vdots     & \\vdots     & \\ddots & \\vdots   & \\cdots & \\vdots         & \\ddots & \\vdots\\\\\n",
        "\\mathbf{1} & r^{(1,1)}_1 & r^{(1,1)}_2 & \\cdots & r^{(1,1)}_{N-1} & r^{(1,1)}_N & r^{(1,2)}_1 & \\cdots & r^{(1,2)}_N & \\cdots & r^{(\\nu,p)}_1 & \\cdots & r^{(\\nu,p)}_N\\\\\n",
        "\\mathbf{1} & r^{(1,1)}_2 & r^{(1,1)}_3 & \\cdots &r^{(1,1)}_{N} & r^{(1,1)}_{N+1} & r^{(1,2)}_2 & \\cdots & r^{(1,2)}_{N+1} & \\cdots & r^{(\\nu,p)}_2 & \\cdots & r^{(\\nu,p)}_{N+1}\\\\\n",
        "\\vdots   & \\vdots     & \\vdots     & \\ddots & \\vdots     & \\vdots     & \\vdots     & \\ddots & \\vdots   & \\cdots & \\vdots         & \\ddots & \\vdots\\\\\n",
        "\\mathbf{1} & r^{(1,1)}_{M-N+1} & r^{(1,1)}_{M-N+2} & \\cdots & r^{(1,1)}_{M-1} & r^{(1,1)}_M & r^{(1,2)}_{M-N+1} & \\cdots & r^{(1,2)}_M & \\cdots & r^{(\\nu,p)}_{M-N+1} & \\cdots & r^{(\\nu,p)}_M\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkrRTSYm3qlA"
      },
      "source": [
        "This is also referred to as the design or feature matrix, with each column being a predictor, or feature. The column of 1’s accounts for the intercept term in linear regression/decoding. Here we are repeating the first windows $N-1$ times as the padding of the first windows. Make sure you understand what this matrix means before moving on.\n",
        "\n",
        "We denote the target matrix as $Y \\in \\mathbb{R}^{M \\times 5}$ and the prediction matrix (e.g. the predicted finger angles) as $\\hat{Y} \\in \\mathbb{R}^{M \\times 5}$. Note that in Warland et al., 1997, this quantity is referred to as the stimulus vector since they are talking about decoding the stimulus from neural data after it. We, on the other hand, are trying to decode finger positions using the ECoG data before it, but we can conveniently use the same method. Our goal is to find some optimal weight matrix or filter $f \\in \\mathbb{R}^{(1+N \\cdot p \\cdot \\nu ) \\times 5}$ that minimizes the mean squared error:\n",
        "\n",
        "$$f^* = \\operatorname{argmin}_{f} \\, \\mathcal{L}(f) = \\operatorname{argmin}_{f} \\left\\|Y - \\hat{Y}\\right\\|^2,$$\n",
        "where $\\hat{Y} = Rf$\n",
        "\n",
        "We start with the mean squared error (MSE) loss function:\n",
        "$$\n",
        "\\mathcal{L}(f) = \\left\\|Y - R\\,f\\right\\|^2 = (Y - R\\,f)^\\top (Y - R\\,f)\n",
        "$$\n",
        "\n",
        "To minimize the loss, we take the derivative with respect to the weight matrix $f$ and set it equal to zero:\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial f} = -2\\,R^\\top (Y - R\\,f) = 0\n",
        "$$\n",
        "\n",
        "This implies:\n",
        "$$\n",
        "R^\\top Y = R^\\top R\\,f\n",
        "$$\n",
        "\n",
        "Assuming that $R^\\top R$ is invertible, we solve for $f$:\n",
        "$$\n",
        "f = \\left(R^\\top R\\right)^{-1} R^\\top Y\n",
        "$$\n",
        "\n",
        "This is the the analytic form for the optimal filter $f$ that minimizes the MSE loss.\n",
        "\n",
        "This equation should take a familiar form. Warland et al., 1997 don’t refer to it as such, but this is exactly the same as linear regression, one of the most commonly used algorithms in practical machine learning. Not only is this algorithm remarkably powerful, but it has a beautiful analytic form for learning the “weights” (here, the $f$ matrix), a rarity in a field where almost all optimizations involve some sort of iterative algorithm. After learning the filter weights $f$, we can calculate the optimal predictions as: $$\\hat{Y} = Rf$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Nbsp0F1V_6"
      },
      "source": [
        "## Dataset\n",
        "The dataset for part 1 is stored within `final_proj_part1_data.pkl`. The `.pkl` file type is a pickle file, which stores python objects. You can open the `.pkl` file with this code.\n",
        "```\n",
        "with open('final_proj_part1_data.pkl', 'rb') as f:\n",
        "  proj_data = pickle.load(f)\n",
        "```\n",
        "This stores the data inside the file as a variable named proj_data.\n",
        "\n",
        "**NOTE: Python versions don't pickle with each other very well. This pickle file was made in Google Colab. If you are running your own installation of Python and cannot load the file, we recommend you use Colab**\n",
        "\n",
        "There are 3 subjects, each with their own Data Glove data (the glove they used to capture hand movements), and ECoG data. The data is represented as a dictionary with keys `'data_glove'` and `'ecog'`, storing the data glove and ecog data, respectively. These keys map to python lists of 3 items. Each item is an np.ndarray corresponding to a subject's data. See the pseudcode below.\n",
        "\n",
        "```\n",
        "proj_data = {\n",
        "  'data_glove':[np.ndarray for subject 1, np.ndarray for subject 2, np.ndarray for subject 3],\n",
        "  'ecog':[np.ndarray for subject 1, np.ndarray for subject 2, np.ndarray for subject 3]\n",
        "}\n",
        "```\n",
        "\n",
        "All np.ndarray shapes for `'data_glove'` should be $(T,5)$, where $T$ is the number of samples in the signal, and 5 is the number of fingers.\n",
        "\n",
        "The np.ndarray shapes for `'ecog'` are $(T, 61)$, $(T, 46)$, and $(T,64)$, where T is the number of samples in the signal, and each subject had 61, 46, and 64 ecog channels, respectively.\n",
        "\n",
        "**The sampling rate of the data glove and ecog was 1000 Hz**\n",
        "\n",
        "<!-- The dataset is also on IEEG\n",
        "* Subject 1\n",
        " * I521_Sub1_Training_ecog - Training ECoG \\\n",
        " * I521_Sub1_Training_dg - Training Data Glove \\\n",
        " * I521_Sub1_Leaderboard_ecog - Testing ECoG\n",
        "* Subject 2\n",
        " * I521_Sub2_Training_ecog - Training ECoG \\\n",
        " * I521_Sub2_Training_dg - Training Data Glove \\\n",
        " * I521_Sub2_Leaderboard_ecog - Testing ECoG\n",
        "* Subject 3\n",
        " * I521_Sub3_Training_ecog - Training ECoG \\\n",
        " * I521_Sub3_Training_dg - Training Data Glove \\\n",
        " * I521_Sub3_Leaderboard_ecog - Testing ECoG -->\n",
        "\n",
        "Your task is to develop an algorithm to use the ECoG to predict finger movements that are captured by the Data Glove."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLzcML-x6jnB"
      },
      "source": [
        "# 1. Getting Started (4 pts)\n",
        "The following sections will walk you through the development of the prediction pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.882195Z",
          "start_time": "2025-03-24T22:12:01.879651Z"
        },
        "id": "8w4AGrXqUt5Q"
      },
      "outputs": [],
      "source": [
        "#Set up the notebook environment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from scipy.stats import pearsonr\n",
        "from scipy import signal as sig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA2hB_8a_Lu3"
      },
      "source": [
        "## 1.\n",
        "Extract the dataglove and ECoG data for each subject from the pickle file. Feel free to copy the code snippet above. Split the data into a training and testing set (at least 50% of the data should be in the training set).\n",
        "\n",
        "**How many samples are there in the full ECoG recording (before splitting)?** (1 pt)\n",
        "\n",
        "**How many samples do you have in your training set? In your testing set?** (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('final_proj_part1_data.pkl', 'rb') as f:\n",
        "    proj_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.915534Z",
          "start_time": "2025-03-24T22:12:01.913199Z"
        },
        "id": "QhWQLBAN_1JP"
      },
      "outputs": [],
      "source": [
        "data_glove = proj_data[\"data_glove\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.11974525, -0.36549759, -0.73717308, -0.51092148, -0.71658897],\n",
              "        [-0.11974525, -0.36549759, -0.73717308, -0.51092148, -0.71658897],\n",
              "        [-0.11974525, -0.36549759, -0.73717308, -0.51092148, -0.71658897],\n",
              "        ...,\n",
              "        [ 2.0240593 , -0.35267067, -0.19278526, -0.19677258, -0.27182388],\n",
              "        [ 2.00303459, -0.35165787, -0.19276047, -0.19695473, -0.27204323],\n",
              "        [ 1.98193359, -0.3506403 , -0.19273472, -0.19713593, -0.27226353]],\n",
              "       shape=(300000, 5)),\n",
              " array([[-0.69935513, -0.12379456, -0.20017529,  4.42933369, -0.51332283],\n",
              "        [-0.69935513, -0.12379456, -0.20017529,  4.42933369, -0.51332283],\n",
              "        [-0.69935513, -0.12379456, -0.20017529,  4.42933369, -0.51332283],\n",
              "        ...,\n",
              "        [-0.59470844,  0.30090046, -0.35142422,  0.05770493,  0.04432487],\n",
              "        [-0.59465694,  0.30065536, -0.35142422,  0.0579443 ,  0.04527092],\n",
              "        [-0.59460258,  0.30041122, -0.35142326,  0.05818367,  0.04621601]],\n",
              "       shape=(300000, 5)),\n",
              " array([[-0.00501347,  0.68820906,  2.57802963,  0.48578787,  0.02674103],\n",
              "        [-0.00501347,  0.68820906,  2.57802963,  0.48578787,  0.02674103],\n",
              "        [-0.00501347,  0.68820906,  2.57802963,  0.48578787,  0.02674103],\n",
              "        ...,\n",
              "        [-0.24686241, -0.94949675, -0.25215101, -0.45340061, -0.56300163],\n",
              "        [-0.24658966, -0.94949961, -0.25224686, -0.45382118, -0.56321907],\n",
              "        [-0.24631977, -0.94950056, -0.25234175, -0.45423698, -0.56343555]],\n",
              "       shape=(300000, 5))]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "ecog = proj_data[\"ecog\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[  612, -1490,  -996, ...,   205,  1046,  -214],\n",
              "        [  814, -1367,  -649, ...,   399,  1241,   -71],\n",
              "        [ 1111, -1182,  -318, ...,   642,  1459,    64],\n",
              "        ...,\n",
              "        [   83,  2673,  1550, ...,   790,  1269, -2325],\n",
              "        [  421,  2650,  1402, ...,   587,  1177, -2254],\n",
              "        [  823,  2686,  1346, ...,   507,  1155, -2088]],\n",
              "       shape=(300000, 61), dtype=int32),\n",
              " array([[-3900,  -870,  2067, ...,  -229,   639,   185],\n",
              "        [-3837,  -569,  2067, ...,   -21,   883,   279],\n",
              "        [-3664,  -323,  2049, ...,   150,  1048,   354],\n",
              "        ...,\n",
              "        [  227, -1136,   761, ..., -1567, -2540,   136],\n",
              "        [  477, -1107,  1059, ..., -1256, -2096,   246],\n",
              "        [  741, -1094,  1335, ...,  -928, -1680,   344]],\n",
              "       shape=(300000, 46), dtype=int32),\n",
              " array([[ 1888,  -915,   260, ..., -2160,  1388,  -335],\n",
              "        [ 1219, -1187,  -162, ..., -2841,  1065,  -728],\n",
              "        [  992, -1030,   -72, ..., -2947,  1136,  -720],\n",
              "        ...,\n",
              "        [  227,   436,   -61, ...,   566,  1894,  3444],\n",
              "        [  -11,   208,  -420, ...,   159,  1796,  3399],\n",
              "        [ -196,    58,  -675, ...,  -187,  1723,  3385]],\n",
              "       shape=(300000, 64), dtype=int32)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ecog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEoLhYHT_2Qr"
      },
      "source": [
        "There are 300,0000 samples in the full ECoG recording before splitting for each subject. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ecog = []\n",
        "test_ecog = []\n",
        "train_glove = []\n",
        "test_glove = []\n",
        "\n",
        "train_len = int(0.8*len(ecog[0]))\n",
        "\n",
        "for subject_idx in range(3):\n",
        "    ecog_data = proj_data[\"ecog\"][subject_idx]\n",
        "    glove_data = proj_data[\"data_glove\"][subject_idx]\n",
        "    train_ecog.append(ecog_data[:train_len])\n",
        "    test_ecog.append(ecog_data[train_len:])\n",
        "    train_glove.append(glove_data[:train_len])\n",
        "    test_glove.append(glove_data[train_len:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "240000"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 1222,   575,  -936, ...,  2648,  2208,   944],\n",
              "        [ 1318,   469,  -855, ...,  2645,  2193,  1389],\n",
              "        [ 1510,   600,  -469, ...,  2729,  2323,  1866],\n",
              "        ...,\n",
              "        [   83,  2673,  1550, ...,   790,  1269, -2325],\n",
              "        [  421,  2650,  1402, ...,   587,  1177, -2254],\n",
              "        [  823,  2686,  1346, ...,   507,  1155, -2088]],\n",
              "       shape=(60000, 61), dtype=int32),\n",
              " array([[ -839,  2907,  2295, ...,   959,   136,   587],\n",
              "        [ -818,  2866,  2203, ...,  1082,   486,   735],\n",
              "        [ -772,  2883,  2024, ...,  1251,   803,   898],\n",
              "        ...,\n",
              "        [  227, -1136,   761, ..., -1567, -2540,   136],\n",
              "        [  477, -1107,  1059, ..., -1256, -2096,   246],\n",
              "        [  741, -1094,  1335, ...,  -928, -1680,   344]],\n",
              "       shape=(60000, 46), dtype=int32),\n",
              " array([[4401, 1578, 3111, ..., 1472, 3515, 1590],\n",
              "        [4349, 1411, 2866, ..., 1362, 3325, 1268],\n",
              "        [3966,  951, 2411, ...,  912, 2820,  745],\n",
              "        ...,\n",
              "        [ 227,  436,  -61, ...,  566, 1894, 3444],\n",
              "        [ -11,  208, -420, ...,  159, 1796, 3399],\n",
              "        [-196,   58, -675, ..., -187, 1723, 3385]],\n",
              "       shape=(60000, 64), dtype=int32)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_ecog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 240,000 samples in my training set and 60,000 samples in my testing set after I split them up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ9Nl70hkHBa"
      },
      "source": [
        "## 2.\n",
        "Next, complete the `filter_data` function. Test it using the raw data extracted in the prior step. What filter types and cutoff frequencies did you use? (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.921163Z",
          "start_time": "2025-03-24T22:12:01.915534Z"
        },
        "id": "CqfertGZGuYQ"
      },
      "outputs": [],
      "source": [
        "def filter_data(raw_eeg, fs=1000):\n",
        "  \"\"\"\n",
        "  Write a filter function to clean underlying data.\n",
        "  Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
        "  Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
        "  distorting the underlying data!\n",
        "\n",
        "  Input:\n",
        "    raw_eeg (samples x channels): the raw signal\n",
        "    fs: the sampling rate (1000 for this dataset)\n",
        "  Output:\n",
        "    clean_data (samples x channels): the filtered signal\n",
        "  \"\"\"\n",
        "  # Define the filter parameters\n",
        "  lowcut = 1.0  # Low cutoff frequency in Hz\n",
        "  highcut = 50.0  # High cutoff frequency in Hz\n",
        "  order = 4  # Filter order\n",
        "  nyquist_freq = 0.5 * fs  # Nyquist frequency\n",
        "  low = lowcut / nyquist_freq  # Low cutoff frequency in normalized units\n",
        "  high = highcut / nyquist_freq  # High cutoff frequency in normalized units\n",
        "  \n",
        "  # Design the filter\n",
        "  b, a = sig.butter(order, [low, high], btype='bandpass')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.925861Z",
          "start_time": "2025-03-24T22:12:01.921163Z"
        },
        "id": "iPc2lya7_7Af"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC2-Pd81_7__"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ZfISDvuuzI"
      },
      "source": [
        "# 2. Calculating Features (12 points)\n",
        "\n",
        "Here you will complete the `get_windowed_feats` and `get_features` functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL3CMDPovL3l"
      },
      "source": [
        "## 1.\n",
        "We will calculate features across sliding time windows. if we use a suggested window length of 100ms with a 50ms window overlap, how many feature windows, $M$, will we have if we computed features using all the data in a given subject? Feel free to re-use code from previous homeworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.937092Z",
          "start_time": "2025-03-24T22:12:01.934644Z"
        },
        "id": "Gc5y0fcb__N3"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUFxdvR8AAMk"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBBgRW2WwMFN"
      },
      "source": [
        "## 2.\n",
        "Now complete the `get_features` function. Please create **4 or more** different features to calculate for each channel in each time window. Features may include the average time-domain voltage, or the average frequency-domain magnitude in consecutive 15Hz frequency bands, bandpower of relevant frequency bands, etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.969410Z",
          "start_time": "2025-03-24T22:12:01.967096Z"
        },
        "id": "yawiKb_ov4Ko"
      },
      "outputs": [],
      "source": [
        "def get_features(filtered_window, fs=1000):\n",
        "  \"\"\"\n",
        "    Write a function that calculates features for a given filtered window.\n",
        "    Feel free to use features you have seen before in this class, features that\n",
        "    have been used in the literature, or design your own!\n",
        "\n",
        "    Input:\n",
        "      filtered_window (window_samples x channels): the window of the filtered ecog signal\n",
        "      fs: sampling rate\n",
        "    Output:\n",
        "      features (channels x num_features): the features calculated on each channel for the window\n",
        "  \"\"\"\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPbDhVki7MnS"
      },
      "source": [
        "## 3.\n",
        "Now finish the `get_windowed_feats` function by putting the `filter_data` and `get_features` functions together to return a feature vector for each time window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.982330Z",
          "start_time": "2025-03-24T22:12:01.979405Z"
        },
        "id": "STXDXJz27qZA"
      },
      "outputs": [],
      "source": [
        "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
        "  \"\"\"\n",
        "    Write a function which processes data through the steps of filtering and\n",
        "    feature calculation and returns features. Points will be awarded for completing\n",
        "    each step appropriately (note that if one of the functions you call within this script\n",
        "    returns a bad output, you won't be double penalized). Note that you will need\n",
        "    to run the filter_data and get_features functions within this function.\n",
        "\n",
        "    Inputs:\n",
        "      raw_eeg (samples x channels): the raw signal\n",
        "      fs: the sampling rate (1000 for this dataset)\n",
        "      window_length: the window's length\n",
        "      window_overlap: the window's overlap\n",
        "    Output:\n",
        "      all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
        "        note that this is a 2D array.\n",
        "  \"\"\"\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tNcrgHN5A8G"
      },
      "source": [
        "# 3. Creating the Response Matrix (6 points)\n",
        "In this section, you will develop code for your *create_R_matrix* function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ni3kkMb5JnD"
      },
      "source": [
        "## 1.\n",
        "For our set of 62 channels in subject 1, what would the dimensions of the $R$ matrix be if we calculated 6 different feature types per channel, and $N = 3$ time bins where the number of total time bins $M$ is the number you calculated in 2.1? (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.986859Z",
          "start_time": "2025-03-24T22:12:01.983328Z"
        },
        "id": "sERDgCJaAdWs"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYccl9qBAdZr"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDwxvZ7k5YNv"
      },
      "source": [
        "## 2.\n",
        "We do not have feature data to fill out the first $N-1$ data rows in the R matrix that will be used to predict the first $N-1$ finger angles. One way to work around this is to append a copy of the first rows $N-1$ times of your feature matrix to the beginning of your feature matrix before calculating R. Make this adjustment in `create_R_matrix`, then compute the response matrix R. You can test whether your function is running correctly by running `create_R_matrix` with data from `testRfunction.pkl` using 3 windows and verifying that the quantity `np.mean(R)` is 25.4669 (5 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.992334Z",
          "start_time": "2025-03-24T22:12:01.986859Z"
        },
        "id": "B78sAA7p4Pr6"
      },
      "outputs": [],
      "source": [
        "def create_R_matrix(features, N_wind):\n",
        "  \"\"\"\n",
        "  Write a function to calculate the R matrix\n",
        "\n",
        "  Input:\n",
        "    features (num_windows x (channels x features)):\n",
        "      the features you calculated using get_windowed_feats\n",
        "    N_wind: number of windows to use in the R matrix\n",
        "\n",
        "  Output:\n",
        "    R (samples x (N_wind*channels*features))\n",
        "  \"\"\"\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:01.997296Z",
          "start_time": "2025-03-24T22:12:01.993331Z"
        },
        "id": "Yn5_Ox0PAi97"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMW0NJ9lAkSa"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRc82EMdfux"
      },
      "source": [
        "# 4. ML Training and Testing (10 points)\n",
        "Here we will use the optimal linear decoder framework to predict finger angles, and additionally you will use one or more models of your own choosing to make the prediction.\n",
        "\n",
        "NOTE: This is a regression task - we are asking you to predict the movement of each finger for each subject."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-x6Ejq-dotg"
      },
      "source": [
        "## 1.\n",
        "\n",
        "Calculate the linear filter $f$ as defined above for all 5 finger angles using features calculated from your training data. You will have to first down-sample the finger flexion data so that your feature matrix, $R$, and your flexion data have the same number of time windows.\n",
        "\n",
        "You will likely find [np.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) or operator @, and [np.linalg.inv](https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html) to be useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:02.005855Z",
          "start_time": "2025-03-24T22:12:01.997296Z"
        },
        "id": "VAIHnBsMAmd0"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKXA3togAnaH"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joHhIH8YwH5O"
      },
      "source": [
        "## 2.\n",
        "Try one other machine learning models using your features and finger angle labels. Look back through previous homeworks to get some ideas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:02.011765Z",
          "start_time": "2025-03-24T22:12:02.006853Z"
        },
        "id": "c3ZKwmsCwOSC"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyu3cvtaApmf"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDqxnI-zvVN1"
      },
      "source": [
        "## 3.\n",
        "Produce predictions on the testing set for each finger angle.\n",
        "\n",
        "Report your correlations here using the linear filter, and when using the other model(s) that you tried, as follows:\n",
        "\n",
        "> For each subject, calculate the correlation coefficient between the predicted and test finger angles for each finger separately.\n",
        "\n",
        "> You therefore should have 15 correlations: five per subject, with three subjects.\n",
        "\n",
        "You will find  [pearsonr](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) to be helpful and already imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T22:12:02.017165Z",
          "start_time": "2025-03-24T22:12:02.012761Z"
        },
        "id": "IbyHoKlxAsL1"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1KcFQSQAtJd"
      },
      "source": [
        "Your answer here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_ehuowkc1TVO",
        "ZhDgvv4T1X4b",
        "n0Nbsp0F1V_6"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
