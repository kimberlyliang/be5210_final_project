{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Leaderboard version - delete at the end; keep the bottom part only"
      ],
      "metadata": {
        "id": "9GP6xi-JA5mM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_QIqeqE1Rfgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions:\n",
        "\n",
        "the pickle file stores 3 separate betas for each subject"
      ],
      "metadata": {
        "id": "Covt7cthBowC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io, scipy.interpolate\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr\n",
        "import pickle"
      ],
      "metadata": {
        "id": "KcYp4KlADFgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the hidden test set\n",
        "# truetest_data = scipy.io.loadmat(\"truetest_data.mat\")\n",
        "# truetest_data = scipy.io.loadmat(\"truetest_data.mat\")['truetest_data']"
      ],
      "metadata": {
        "id": "lTnWvZYpDkQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the leaderboard data\n",
        "truetest_data = scipy.io.loadmat(\"leaderboard_data.mat\")\n",
        "LBecog = truetest_data['leaderboard_ecog']"
      ],
      "metadata": {
        "id": "yl9iN7snHXhh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "b58875bb-df71-4db9-c2d7-fc4f0f05e5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "could not read bytes",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b585cb816912>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the leaderboard data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtruetest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"leaderboard_data.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mLBecog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruetest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leaderboard_ecog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/io/matlab/_mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/io/matlab/_mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    288\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         '''\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_cells\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_real_complex\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_mio5_utils.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_element\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_streams.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream.read_string\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_streams.pyx\u001b[0m in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream.read_into\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: could not read bytes"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained linear filter\n",
        "with open('allBetas.pkl', 'rb') as f:\n",
        "    allBetas  = pickle.load(f)"
      ],
      "metadata": {
        "id": "Z-3LomxtKKeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(allBetas[0].shape)\n",
        "print(allBetas[1].shape)\n",
        "print(allBetas[2].shape)"
      ],
      "metadata": {
        "id": "hnE4yDxvTGgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_windows(data, window_length, window_overlap, fs=1000):\n",
        "    window_length_samples = int(window_length * fs / 1000)\n",
        "    window_overlap_samples = int(window_overlap * fs / 1000)\n",
        "    num_windows = (data.shape[0] - window_length_samples) // (window_length_samples - window_overlap_samples) + 1\n",
        "    feature_windows = np.zeros((num_windows, window_length_samples, data.shape[1]))\n",
        "    for i in range(num_windows):\n",
        "        start_idx = i * (window_length_samples - window_overlap_samples)\n",
        "        end_idx = start_idx + window_length_samples\n",
        "        feature_windows[i] = data[start_idx:end_idx]\n",
        "    return feature_windows\n",
        "\n",
        "def extract_features(window, fs=1000):\n",
        "    features = []\n",
        "    mean_voltage = np.mean(window, axis=0)\n",
        "    features.append(mean_voltage)\n",
        "    nperseg = window.shape[0]\n",
        "    f, Pxx = scipy.signal.welch(np.transpose(window), fs=fs, nperseg=nperseg)\n",
        "    bands = [(5, 15), (20, 25), (75, 115), (125, 160), (160, 175)]\n",
        "    for low, high in bands:\n",
        "        mask = (f >= low) & (f <= high)\n",
        "        band_power = np.mean(Pxx[:, mask], axis=1) if np.any(mask) else np.zeros(Pxx.shape[0])\n",
        "        features.append(band_power)\n",
        "    return np.concatenate(features)\n",
        "\n",
        "def cubic_spline_interpolation(y, old_freq, new_freq, total_duration):\n",
        "    old_times = np.linspace(0, total_duration, int(total_duration*old_freq))\n",
        "    new_times = np.linspace(0, total_duration, int(total_duration*new_freq))\n",
        "    new_y = np.zeros((int(total_duration*new_freq), 5))\n",
        "    for columnIndex in range(y.shape[1]):\n",
        "      interpolator = scipy.interpolate.CubicSpline(old_times, y[:, columnIndex], bc_type='clamped')\n",
        "      new_y[:, columnIndex] = interpolator(new_times)\n",
        "    print(new_y.shape)\n",
        "    return new_times, new_y\n",
        "\n",
        "def pad_data(interpolated_data, original_length):\n",
        "    pad_before = (original_length - len(interpolated_data)) // 2\n",
        "    pad_after = original_length - len(interpolated_data) - pad_before\n",
        "    padded_data = np.pad(interpolated_data, ((pad_before, pad_after), (0,0)), mode='constant')\n",
        "    return padded_data\n",
        "\n",
        "def moving_average_interpolated(data, window_size):\n",
        "    num_rows, num_cols = data.shape\n",
        "    smoothed_data = np.zeros_like(data)\n",
        "    for col in range(num_cols):\n",
        "        smoothed_data[:, col] = np.convolve(data[:, col], np.ones(window_size) / window_size, mode='same')\n",
        "    return smoothed_data"
      ],
      "metadata": {
        "id": "HRdZlEz0JNun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace with hidden test set for final submission\n",
        "predicted_dg_python = {}\n",
        "\n",
        "for i in range(len(truetest_data['leaderboard_ecog'])):  # Replace with actual leaderboard data or hidden test set\n",
        "    window_length = 100\n",
        "    window_overlap = 50\n",
        "    pred_windows = gen_windows(truetest_data['leaderboard_ecog'][i][0], window_length, window_overlap)  # Replace with actual leaderboard data or hidden test set\n",
        "\n",
        "    # Generate feature windows and extract features for prediction\n",
        "    pred_features = np.array([extract_features(window) for window in pred_windows])\n",
        "\n",
        "    lagVal = 3  # Make sure this matches the lag value used during training\n",
        "    X_pred = np.array([pred_features[i:i+lagVal].flatten() for i in range(len(pred_features) - lagVal + 1)])\n",
        "\n",
        "    print(\"X_pred shape:\", X_pred.shape)\n",
        "    print(\"beta shape:\", allBetas[i])\n",
        "\n",
        "    # Generate predictions using the pre-trained linear filter\n",
        "    roughPreds = np.matmul(X_pred, allBetas[i])\n",
        "\n",
        "    allPreds = moving_average_interpolated(roughPreds, 8)\n",
        "\n",
        "    # Interpolate and structure for submission\n",
        "    original_length = len(truetest_data['leaderboard_ecog'][i][0])  # Replace with actual leaderboard data or hidden test set\n",
        "    total_duration = len(allPreds) * 0.05\n",
        "\n",
        "    _, interpolated_predictions = cubic_spline_interpolation(allPreds, old_freq=20, new_freq=1000, total_duration=total_duration)\n",
        "    padded_predictions = pad_data(interpolated_predictions, original_length)\n",
        "\n",
        "    predicted_dg_python[f\"Subject {i+1}\"] = padded_predictions\n",
        "\n",
        "# Convert the dictionary to a MATLAB cell array structure\n",
        "# predicted_dg = {'cell_array': scipy.io.matlab.mio5_params.mat_struct()}\n",
        "# for i in range(len(predicted_dg_python)):\n",
        "#     predicted_dg['cell_array'].__dict__[f\"Subject {i+1}\"] = predicted_dg_python[f\"Subject {i+1}\"]\n",
        "\n",
        "# # Save the predictions to 'predicted_dg.mat'\n",
        "# scipy.io.savemat('predicted_dg.mat', predicted_dg)\n",
        "\n",
        "# Convert the dictionary to a MATLAB cell array structure\n",
        "predicted_dg = np.zeros((1, len(predicted_dg_python)), dtype=object)\n",
        "for i in range(len(predicted_dg_python)):\n",
        "    predicted_dg[0, i] = predicted_dg_python[f\"Subject {i+1}\"]\n",
        "\n",
        "predicted_dg_dict = {'predicted_dg': predicted_dg}\n",
        "\n",
        "# Save the predictions to 'predicted_dg.mat'\n",
        "scipy.io.savemat('predicted_dg.mat', predicted_dg_dict)"
      ],
      "metadata": {
        "id": "zKYV9NknZRSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved predicted_dg.mat file\n",
        "loaded_data = scipy.io.loadmat('predicted_dg.mat')\n",
        "\n",
        "# Access the predicted_dg variable from the loaded data\n",
        "predicted_dg = loaded_data['predicted_dg']\n",
        "\n",
        "# Print the shape and data type of predicted_dg\n",
        "print(\"Shape of predicted_dg:\", predicted_dg.shape)\n",
        "print(\"Data type of predicted_dg:\", predicted_dg.dtype)\n",
        "\n",
        "# Iterate over each subject in predicted_dg\n",
        "for i in range(predicted_dg.shape[1]):\n",
        "    subject_data = predicted_dg[0, i]\n",
        "    print(f\"\\nSubject {i+1}:\")\n",
        "    print(\"Shape of subject data:\", subject_data.shape)\n",
        "    print(\"Data type of subject data:\", subject_data.dtype)\n",
        "\n",
        "    # Print a sample of the subject data\n",
        "    print(\"Sample of subject data:\")\n",
        "    print(subject_data[:5, :])"
      ],
      "metadata": {
        "id": "bJbtc13TKt1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Algorithm Submission"
      ],
      "metadata": {
        "id": "IkVIbxjgDMrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instructions\n",
        "\n",
        "Upload the following: truetest_data.mat (the hidden test set), allBetas.pkl (the pre-trained linear filter), and run the Final_Format.ipynb script.\n",
        "\n",
        "The script will load the hidden test set, apply the pre-trained linear filter, generate predictions, and save the predictions to a file named predicted_dg.mat.\n",
        "\n",
        "Download the predicted_dg.mat file from Google Colab, which contains the predicted finger flexion values for the hidden test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "XlsRP3ZRDO43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io, scipy.interpolate\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr\n",
        "import pickle\n",
        "\n",
        "# Load the hidden test set\n",
        "truetest_data = scipy.io.loadmat(\"truetest_data.mat\")\n",
        "\n",
        "# Load the pre-trained linear filter\n",
        "with open('allBetas.pkl', 'rb') as f:\n",
        "    allBetas  = pickle.load(f)\n",
        "\n",
        "print(allBetas[0].shape)\n",
        "print(allBetas[1].shape)\n",
        "print(allBetas[2].shape)\n",
        "\n",
        "def gen_windows(data, window_length, window_overlap, fs=1000):\n",
        "    window_length_samples = int(window_length * fs / 1000)\n",
        "    window_overlap_samples = int(window_overlap * fs / 1000)\n",
        "    num_windows = (data.shape[0] - window_length_samples) // (window_length_samples - window_overlap_samples) + 1\n",
        "    feature_windows = np.zeros((num_windows, window_length_samples, data.shape[1]))\n",
        "    for i in range(num_windows):\n",
        "        start_idx = i * (window_length_samples - window_overlap_samples)\n",
        "        end_idx = start_idx + window_length_samples\n",
        "        feature_windows[i] = data[start_idx:end_idx]\n",
        "    return feature_windows\n",
        "\n",
        "def extract_features(window, fs=1000):\n",
        "    features = []\n",
        "    mean_voltage = np.mean(window, axis=0)\n",
        "    features.append(mean_voltage)\n",
        "    nperseg = window.shape[0]\n",
        "    f, Pxx = scipy.signal.welch(np.transpose(window), fs=fs, nperseg=nperseg)\n",
        "    bands = [(5, 15), (20, 25), (75, 115), (125, 160), (160, 175)]\n",
        "    for low, high in bands:\n",
        "        mask = (f >= low) & (f <= high)\n",
        "        band_power = np.mean(Pxx[:, mask], axis=1) if np.any(mask) else np.zeros(Pxx.shape[0])\n",
        "        features.append(band_power)\n",
        "    return np.concatenate(features)\n",
        "\n",
        "def cubic_spline_interpolation(y, old_freq, new_freq, total_duration):\n",
        "    old_times = np.linspace(0, total_duration, int(total_duration*old_freq))\n",
        "    new_times = np.linspace(0, total_duration, int(total_duration*new_freq))\n",
        "    new_y = np.zeros((int(total_duration*new_freq), 5))\n",
        "    for columnIndex in range(y.shape[1]):\n",
        "      interpolator = scipy.interpolate.CubicSpline(old_times, y[:, columnIndex], bc_type='clamped')\n",
        "      new_y[:, columnIndex] = interpolator(new_times)\n",
        "    print(new_y.shape)\n",
        "    return new_times, new_y\n",
        "\n",
        "def pad_data(interpolated_data, original_length):\n",
        "    pad_before = (original_length - len(interpolated_data)) // 2\n",
        "    pad_after = original_length - len(interpolated_data) - pad_before\n",
        "    padded_data = np.pad(interpolated_data, ((pad_before, pad_after), (0,0)), mode='constant')\n",
        "    return padded_data\n",
        "\n",
        "def moving_average_interpolated(data, window_size):\n",
        "    num_rows, num_cols = data.shape\n",
        "    smoothed_data = np.zeros_like(data)\n",
        "    for col in range(num_cols):\n",
        "        smoothed_data[:, col] = np.convolve(data[:, col], np.ones(window_size) / window_size, mode='same')\n",
        "    return smoothed_data\n",
        "\n",
        "# replace with hidden test set for final submission\n",
        "predicted_dg_python = {}\n",
        "\n",
        "for i in range(len(truetest_data)):\n",
        "    window_length = 100\n",
        "    window_overlap = 50\n",
        "    pred_windows = gen_windows(truetest_data[i][0], window_length, window_overlap)\n",
        "\n",
        "    # Generate feature windows and extract features for prediction\n",
        "    pred_features = np.array([extract_features(window) for window in pred_windows])\n",
        "\n",
        "    lagVal = 3  # Make sure this matches the lag value used during training\n",
        "    X_pred = np.array([pred_features[i:i+lagVal].flatten() for i in range(len(pred_features) - lagVal + 1)])\n",
        "\n",
        "    print(\"X_pred shape:\", X_pred.shape)\n",
        "    print(\"beta shape:\", allBetas[i].shape)\n",
        "\n",
        "    # Generate predictions using the pre-trained linear filter\n",
        "    roughPreds = np.matmul(X_pred, allBetas[i])\n",
        "\n",
        "    allPreds = moving_average_interpolated(roughPreds, 8)\n",
        "\n",
        "    # Interpolate and structure for submission\n",
        "    original_length = len(truetest_data[i][0])\n",
        "    total_duration = len(allPreds) * 0.05\n",
        "\n",
        "    _, interpolated_predictions = cubic_spline_interpolation(allPreds, old_freq=20, new_freq=1000, total_duration=total_duration)\n",
        "    padded_predictions = pad_data(interpolated_predictions, original_length)\n",
        "\n",
        "    predicted_dg_python[f\"Subject {i+1}\"] = padded_predictions\n",
        "\n",
        "# Convert the dictionary to a MATLAB cell array structure\n",
        "predicted_dg = {'cell_array': scipy.io.matlab.mio5_params.mat_struct()}\n",
        "for i in range(len(predicted_dg_python)):\n",
        "    predicted_dg['cell_array'].__dict__[f\"Subject {i+1}\"] = predicted_dg_python[f\"Subject {i+1}\"]\n",
        "\n",
        "# Save the predictions to 'predicted_dg.mat'\n",
        "scipy.io.savemat('predicted_dg.mat', predicted_dg)"
      ],
      "metadata": {
        "id": "VxIOjsxMChfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# suggested modif\n",
        "# Convert the dictionary to a MATLAB cell array structure\n",
        "predicted_dg = np.zeros((1, len(predicted_dg_python)), dtype=object)\n",
        "for i in range(len(predicted_dg_python)):\n",
        "    predicted_dg[0, i] = predicted_dg_python[f\"Subject {i+1}\"]\n",
        "\n",
        "predicted_dg_dict = {'predicted_dg': predicted_dg}\n",
        "\n",
        "# Save the predictions to 'predicted_dg.mat'\n",
        "scipy.io.savemat('predicted_dg.mat', predicted_dg_dict)"
      ],
      "metadata": {
        "id": "9zcsNwviHbPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}