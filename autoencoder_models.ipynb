{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877f816f",
   "metadata": {},
   "source": [
    "# FingerFlex Model with Original Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8f3e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "from scipy import signal as sig\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67abe770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(raw_eeg, fs=1000):\n",
    "  def notch_filter(data, freq, fs, Q=30):\n",
    "      \"\"\"Apply a notch filter at a specific frequency.\"\"\"\n",
    "      b, a = sig.iirnotch(w0=freq/(fs/2), Q=Q)\n",
    "      return sig.filtfilt(b, a, data, axis=0)\n",
    "\n",
    "  def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "      \"\"\"Apply a Butterworth bandpass filter.\"\"\"\n",
    "      nyq = 0.5 * fs\n",
    "      low = lowcut / nyq\n",
    "      high = highcut / nyq\n",
    "      b, a = sig.butter(order, [low, high], btype='band')\n",
    "      return sig.filtfilt(b, a, data, axis=0)\n",
    "\n",
    "    # Apply notch filters at 60 Hz harmonics (up to 300 Hz)\n",
    "  filtered = raw_eeg.copy()\n",
    "  for freq in [60, 120, 180, 240, 300]:\n",
    "      filtered = notch_filter(filtered, freq, fs)\n",
    "\n",
    "    # Apply bandpass filter (default 1â€“200 Hz)\n",
    "  clean_data = bandpass_filter(filtered, lowcut=1, highcut=200, fs=fs)\n",
    "\n",
    "  return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c8f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(ecog_data, glove_data, win_len=256, step=128, delay=2):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(ecog_data) - win_len - delay, step):\n",
    "        window = ecog_data[i:i+win_len]\n",
    "        label = glove_data[i+delay:i+delay+win_len]\n",
    "        X.append(window)\n",
    "        Y.append(label)\n",
    "    return np.stack(X), np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c64f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerFlexDataset(Dataset):\n",
    "    def __init__(self, ecog, glove):\n",
    "        self.X = torch.tensor(ecog, dtype=torch.float32).permute(0, 2, 1)\n",
    "        self.Y = torch.tensor(glove, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e74601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerFlexModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels=5):\n",
    "        super(FingerFlexModel, self).__init__()\n",
    "        \n",
    "        self.enc1 = self.block(input_channels, 32)\n",
    "        print(f\"enc1 initialized: input={input_channels}, output=32\")\n",
    "        \n",
    "        self.enc2 = self.block(32, 32)\n",
    "        print(f\"enc2 initialized: input=32, output=32\")\n",
    "        \n",
    "        self.enc3 = self.block(32, 64)\n",
    "        print(f\"enc3 initialized: input=32, output=64\")\n",
    "        \n",
    "        self.enc4 = self.block(64, 64)\n",
    "        print(f\"enc4 initialized: input=64, output=64\")\n",
    "        \n",
    "        self.enc5 = self.block(64, 128)\n",
    "        print(f\"enc5 initialized: input=64, output=128\")\n",
    "        \n",
    "        self.enc6 = self.block(128, 128)\n",
    "        print(f\"enc6 initialized: input=128, output=128\")\n",
    "        \n",
    "        self.dec1 = self.up(128, 128)\n",
    "        print(f\"dec1 initialized: input=128, output=128\")\n",
    "        \n",
    "        self.dec2 = self.up(256, 64)  # 128 + 128 = 256 input\n",
    "        print(f\"dec2 initialized: input=256, output=64\")\n",
    "        \n",
    "        self.dec3 = self.up(128, 64)  # 64 + 64 = 128 input\n",
    "        print(f\"dec3 initialized: input=128, output=64\")\n",
    "        \n",
    "        self.dec4 = self.up(128, 32)  # 64 + 64 = 128 i\n",
    "\n",
    "    def block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm(out_c),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f\"\\nForward pass:\")\n",
    "        print(f\"Input shape: {x.shape}\")  # [1, 62, 240000]\n",
    "        s = []\n",
    "        \n",
    "        # First encoder block\n",
    "        print(\"\\nEncoder Block 1:\")\n",
    "        x1 = self.enc1(x)\n",
    "        print(f\"After Conv1d: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After LayerNorm: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After GELU: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After Dropout: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After MaxPool: {x1.shape}\")  # [1, 32, 120000]\n",
    "        s.append(x1)\n",
    "        \n",
    "        # Second encoder block\n",
    "        print(\"\\nEncoder Block 2:\")\n",
    "        x2 = self.enc2(x1)\n",
    "        print(f\"After Conv1d: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After LayerNorm: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After GELU: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After Dropout: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After MaxPool: {x2.shape}\")  # [1, 32, 60000]\n",
    "        s.append(x2)\n",
    "        \n",
    "        # Continue with other blocks...\n",
    "        x3 = self.enc3(x2); s.append(x3)\n",
    "        x4 = self.enc4(x3); s.append(x4)\n",
    "        x5 = self.enc5(x4); s.append(x5)\n",
    "        x6 = self.enc6(x5)\n",
    "        \n",
    "        # Decoder blocks\n",
    "        d1 = self.dec1(x6)\n",
    "        d2 = self.dec2(torch.cat([d1, s[4]], dim=1))\n",
    "        d3 = self.dec3(torch.cat([d2, s[3]], dim=1))\n",
    "        d4 = self.dec4(torch.cat([d3, s[2]], dim=1))\n",
    "        d5 = self.dec5(torch.cat([d4, s[1]], dim=1))\n",
    "        \n",
    "        out = self.final(torch.cat([d5, s[0]], dim=1))\n",
    "        return out.permute(0, 2, 1)\n",
    "    \n",
    "    # def block(self, in_c, out_c):\n",
    "    #     return nn.Sequential(\n",
    "    #         nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
    "    #         nn.LayerNorm(out_c),\n",
    "    #         nn.GELU(),\n",
    "    #         nn.Dropout(0.1),\n",
    "    #         nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "    #     )\n",
    "    \n",
    "    def up(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        )\n",
    "    # def forward(self, x):\n",
    "    #     print(f\"\\nInput shape: {x.shape}\")\n",
    "    #     s = []\n",
    "        \n",
    "    #     x1 = self.enc1(x); s.append(x1)\n",
    "    #     print(f\"After enc1: {x1.shape}\")\n",
    "        \n",
    "    #     x2 = self.enc2(x1); s.append(x2)\n",
    "    #     print(f\"After enc2: {x2.shape}\")\n",
    "        \n",
    "    #     x3 = self.enc3(x2); s.append(x3)\n",
    "    #     print(f\"After enc3: {x3.shape}\")\n",
    "        \n",
    "    #     x4 = self.enc4(x3); s.append(x4)\n",
    "    #     print(f\"After enc4: {x4.shape}\")\n",
    "        \n",
    "    #     x5 = self.enc5(x4); s.append(x5)\n",
    "    #     print(f\"After enc5: {x5.shape}\")\n",
    "        \n",
    "    #     x6 = self.enc6(x5)\n",
    "    #     print(f\"After enc6: {x6.shape}\")\n",
    "        \n",
    "    #     d1 = self.dec1(x6)\n",
    "    #     print(f\"After dec1: {d1.shape}\")\n",
    "        \n",
    "    #     d2 = self.dec2(torch.cat([d1, s[4]], dim=1))\n",
    "    #     print(f\"After dec2: {d2.shape}\")\n",
    "        \n",
    "    #     d3 = self.dec3(torch.cat([d2, s[3]], dim=1))\n",
    "    #     print(f\"After dec3: {d3.shape}\")\n",
    "        \n",
    "    #     d4 = self.dec4(torch.cat([d3, s[2]], dim=1))\n",
    "    #     print(f\"After dec4: {d4.shape}\")\n",
    "        \n",
    "    #     d5 = self.dec5(torch.cat([d4, s[1]], dim=1))\n",
    "    #     print(f\"After dec5: {d5.shape}\")\n",
    "        \n",
    "    #     out = self.final(torch.cat([d5, s[0]], dim=1))\n",
    "    #     print(f\"After final: {out.shape}\")\n",
    "        \n",
    "    #     return out.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436a1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, dilation=1, p_conv_drop=0.1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, \n",
    "                               kernel_size=kernel_size, \n",
    "                               bias=False, \n",
    "                               padding='same')\n",
    "        \n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "        self.drop = nn.Dropout(p=p_conv_drop)\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=stride, stride=stride)\n",
    "\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        \n",
    "        # norm by last axis\n",
    "        x = torch.transpose(x, -2, -1) \n",
    "        x = self.norm(x)\n",
    "        x = torch.transpose(x, -2, -1)\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, scale, **args):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "        self.conv_block = ConvBlock(**args)\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode='linear', align_corners=False)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.upsample(x)\n",
    "        return x    \n",
    "\n",
    "class AutoEncoder1D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_electrodes=62,   # Number of channels (ECoG electrodes)\n",
    "                 n_freqs=1,         # Number of frequency bands (1 for raw data)\n",
    "                 n_channels_out=5,  # Number of fingers to predict\n",
    "                 channels=[32, 64, 128, 128],  # Number of features on each encoder layer\n",
    "                 kernel_sizes=[3, 3, 3],\n",
    "                 strides=[2, 2, 2],  # Reduced stride to handle long sequences\n",
    "                 dilation=[1, 1, 1]\n",
    "                 ):\n",
    "        \n",
    "        super(AutoEncoder1D, self).__init__()\n",
    "        \n",
    "        self.n_electrodes = n_electrodes\n",
    "        self.n_freqs = n_freqs\n",
    "        self.n_inp_features = n_freqs * n_electrodes\n",
    "        self.n_channels_out = n_channels_out\n",
    "        \n",
    "        self.model_depth = len(channels)-1\n",
    "        \n",
    "        # Initial dimensionality reduction\n",
    "        self.spatial_reduce = ConvBlock(self.n_inp_features, channels[0], kernel_size=3)\n",
    "        \n",
    "        # Encoder part\n",
    "        self.downsample_blocks = nn.ModuleList([\n",
    "            ConvBlock(channels[i], channels[i+1], \n",
    "                     kernel_sizes[i],\n",
    "                     stride=strides[i], \n",
    "                     dilation=dilation[i]) \n",
    "            for i in range(self.model_depth)\n",
    "        ])\n",
    "\n",
    "        # Prepare channels for decoder\n",
    "        channels = [ch for ch in channels[:-1]] + channels[-1:]\n",
    "\n",
    "        # Decoder part with skip connections\n",
    "        self.upsample_blocks = nn.ModuleList([\n",
    "            UpConvBlock(scale=strides[i],\n",
    "                       in_channels=channels[i+1] if i == self.model_depth-1 else channels[i+1]*2,\n",
    "                       out_channels=channels[i],\n",
    "                       kernel_size=kernel_sizes[i]) \n",
    "            for i in range(self.model_depth-1, -1, -1)\n",
    "        ])\n",
    "        \n",
    "        # Final 1x1 convolution\n",
    "        self.conv1x1_one = nn.Conv1d(channels[0]*2, self.n_channels_out, kernel_size=1, padding='same')\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch, electrodes, time]\n",
    "        batch, elec, time = x.shape\n",
    "        \n",
    "        # Add frequency dimension if needed\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(2)  # [batch, electrodes, 1, time]\n",
    "            \n",
    "        # Reshape and process\n",
    "        x = x.reshape(batch, -1, time)  # flatten the input\n",
    "        x = self.spatial_reduce(x)\n",
    "        \n",
    "        # Encoder path with skip connections\n",
    "        skip_connections = []\n",
    "        for i in range(self.model_depth):\n",
    "            skip_connections.append(x)\n",
    "            x = self.downsample_blocks[i](x)\n",
    "\n",
    "        # Decoder path with skip connections\n",
    "        for i in range(self.model_depth):\n",
    "            x = self.upsample_blocks[i](x)\n",
    "            x = torch.cat((x, skip_connections[-1 - i]), dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        x = self.conv1x1_one(x)\n",
    "        return x.permute(0, 2, 1)  # [batch, time, fingers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ea88c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    def forward(self, pred, target):\n",
    "        mse = self.mse(pred, target)\n",
    "        cos = F.cosine_similarity(pred, target, dim=-1).mean()\n",
    "        return 0.5 * (mse + (1 - cos))\n",
    "\n",
    "def train_model(model, train_loader, epochs=10, lr=8.4e-5):\n",
    "    model.train()\n",
    "    loss_fn = CombinedLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba0475f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'raw_training_data.mat' # file path\n",
    "test_file = 'leaderboard_data.mat'\n",
    "\n",
    "# load training data\n",
    "train_data = sio.loadmat(train_file) # returns dict with keys and values as numpy arrays\n",
    "ecog = train_data['train_ecog']\n",
    "data_glove = train_data['train_dg']\n",
    "\n",
    "# leaderboard testing data\n",
    "test_data = sio.loadmat(test_file)\n",
    "leaderboard_ecog = test_data['leaderboard_ecog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08e5cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ecog = []\n",
    "test_ecog = []\n",
    "train_glove = []\n",
    "test_glove = []\n",
    "\n",
    "train_len = int(0.8*len(ecog[0][0]))\n",
    "\n",
    "for subject_idx in range(3):\n",
    "    ecog_data = ecog[subject_idx]\n",
    "    glove_data = data_glove[subject_idx]\n",
    "    train_ecog.append(ecog_data[0][:train_len])\n",
    "    test_ecog.append(ecog_data[0][train_len:])\n",
    "    train_glove.append(glove_data[0][:train_len])\n",
    "    test_glove.append(glove_data[0][train_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7178e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1000\n",
    "xLen = len(train_ecog[0])\n",
    "winLen= 0.1\n",
    "winDisp = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82755ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumWins(xLen, fs, winLen, winDisp):\n",
    "  winLen = winLen * fs\n",
    "  winDisp = winDisp * fs\n",
    "  return int((xLen - winLen) // winDisp + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b56a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4799"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumWins(xLen, fs, winLen, winDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a498a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ecogs = [filter_data(ecog) for ecog in train_ecog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c140f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize glove\n",
    "normalized_gloves = [(train_glove_i - train_glove_i.min()) / (train_glove_i.max() - train_glove_i.min()) for train_glove_i in train_glove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24927db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_windows(filtered_ecogs[0], normalized_gloves[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cac2c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "dataset = FingerFlexDataset(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb3d4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4f94b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15c26c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered ECoG tensor shape: torch.Size([1, 62, 240000])\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the array to ensure positive strides\n",
    "filtered_ecog_tensor = torch.from_numpy(filtered_ecogs[0].copy()).float()\n",
    "\n",
    "# Now you can safely transpose and add batch dimension\n",
    "if len(filtered_ecog_tensor.shape) == 2:  # If it's (time_steps, channels)\n",
    "    filtered_ecog_tensor = filtered_ecog_tensor.T  # Transpose to (channels, time_steps)\n",
    "    filtered_ecog_tensor = filtered_ecog_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Filtered ECoG tensor shape:\", filtered_ecog_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2edb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Filtered ECoG tensor shape: torch.Size([1, 240000, 62])\n"
     ]
    }
   ],
   "source": [
    "# Current shape: [1, 240000, 62]\n",
    "# We want: [1, 62, 240000]\n",
    "\n",
    "# First, remove the batch dimension\n",
    "filtered_ecog_tensor = filtered_ecog_tensor.squeeze(0)  # Now [240000, 62]\n",
    "\n",
    "# Then transpose to get channels first\n",
    "filtered_ecog_tensor = filtered_ecog_tensor.T  # Now [62, 240000]\n",
    "\n",
    "# Finally, add batch dimension back\n",
    "filtered_ecog_tensor = filtered_ecog_tensor.unsqueeze(0)  # Now [1, 62, 240000]\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Corrected Filtered ECoG tensor shape:\", filtered_ecog_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52f029ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder1D(\n",
       "  (spatial_reduce): ConvBlock(\n",
       "    (conv1d): Conv1d(62, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (downsample_blocks): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (downsample): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1d): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (downsample): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (downsample): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (upsample_blocks): ModuleList(\n",
       "    (0): UpConvBlock(\n",
       "      (conv_block): ConvBlock(\n",
       "        (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "    )\n",
       "    (1): UpConvBlock(\n",
       "      (conv_block): ConvBlock(\n",
       "        (conv1d): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "    )\n",
       "    (2): UpConvBlock(\n",
       "      (conv_block): ConvBlock(\n",
       "        (conv1d): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "    )\n",
       "  )\n",
       "  (conv1x1_one): Conv1d(64, 5, kernel_size=(1,), stride=(1,), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9fb3730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1749\n",
      "Epoch 2: Loss = 0.1184\n",
      "Epoch 3: Loss = 0.1041\n",
      "Epoch 4: Loss = 0.0960\n",
      "Epoch 5: Loss = 0.0907\n",
      "Epoch 6: Loss = 0.0866\n",
      "Epoch 7: Loss = 0.0833\n",
      "Epoch 8: Loss = 0.0802\n",
      "Epoch 9: Loss = 0.0776\n",
      "Epoch 10: Loss = 0.0753\n",
      "Epoch 11: Loss = 0.0737\n",
      "Epoch 12: Loss = 0.0718\n",
      "Epoch 13: Loss = 0.0706\n",
      "Epoch 14: Loss = 0.0689\n",
      "Epoch 15: Loss = 0.0676\n",
      "Epoch 16: Loss = 0.0662\n",
      "Epoch 17: Loss = 0.0654\n",
      "Epoch 18: Loss = 0.0641\n",
      "Epoch 19: Loss = 0.0635\n",
      "Epoch 20: Loss = 0.0623\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, loader, epochs=20)\n",
    "torch.save(trained_model.state_dict(), 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19b498f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First, load your trained model\n",
    "model = AutoEncoder1D()\n",
    "model.load_state_dict(torch.load('trained_model.pth'))\n",
    "model.eval()  # Set to evaluation mode\n",
    "# 3. Prepare the input data\n",
    "# Convert to tensor and add batch dimension\n",
    "test_ecog_tensor = torch.FloatTensor(test_ecog[0].T)  # [time, channels]\n",
    "test_ecog_tensor = test_ecog_tensor.unsqueeze(0)  # [1, time, channels]\n",
    "\n",
    "# 4. Make predictions\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    predictions = model(test_ecog_tensor)  # [1, time, 5]\n",
    "\n",
    "# 5. Convert predictions to numpy and remove batch dimension\n",
    "predictions = predictions.squeeze(0).numpy()  # [time, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48a9bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32443577, 0.31685024, 0.18314555, 0.13791126, 0.27647138],\n",
       "       [0.20387895, 0.18787694, 0.22293738, 0.24766283, 0.17975752],\n",
       "       [0.21603225, 0.22571966, 0.23749822, 0.21542756, 0.17827828],\n",
       "       ...,\n",
       "       [0.21963586, 0.20924117, 0.21377352, 0.10472213, 0.16552237],\n",
       "       [0.20235266, 0.19962719, 0.22381625, 0.0989549 , 0.17417732],\n",
       "       [0.25801334, 0.18685997, 0.2622264 , 0.22069572, 0.14892665]],\n",
       "      shape=(60000, 5), dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbf170c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, _ = pearsonr(predictions, test_glove[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42589e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03528733,  0.03272834, -0.0168465 ,  0.01353211, -0.00617093])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef675e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 62)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ecog[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ecogs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dff76572",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dummy_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((test_ecog[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m X_test, Y_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_ecogs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m FingerFlexDataset(test_ecog[\u001b[38;5;241m0\u001b[39m], dummy_labels)\n\u001b[1;32m      4\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mcreate_windows\u001b[0;34m(ecog_data, glove_data, win_len, step, delay)\u001b[0m\n\u001b[1;32m      6\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(window)\n\u001b[1;32m      7\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(X), \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/shape_base.py:460\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    458\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    462\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    463\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "dummy_labels = np.zeros((test_ecog[0].shape[0], 5))\n",
    "X_test, Y_test = create_windows(filtered_ecogs[0], dummy_labels)\n",
    "test_dataset = FingerFlexDataset(test_ecog[0], dummy_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for x, _ in test_loader:\n",
    "        preds = model(x)\n",
    "        all_preds.append(preds.numpy())\n",
    "\n",
    "# Stitch results back together\n",
    "predicted_fingers = np.concatenate(all_preds, axis=0)  # Shape: [windows, time, 5]\n",
    "predicted_fingers = predicted_fingers.reshape(-1, 5)[:test_ecog.shape[0]]  # Truncate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
