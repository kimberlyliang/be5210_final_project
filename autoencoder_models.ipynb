{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877f816f",
   "metadata": {},
   "source": [
    "# FingerFlex Model with Original Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8f3e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "from scipy import signal as sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67abe770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(raw_eeg, fs=1000):\n",
    "  def notch_filter(data, freq, fs, Q=30):\n",
    "      \"\"\"Apply a notch filter at a specific frequency.\"\"\"\n",
    "      b, a = sig.iirnotch(w0=freq/(fs/2), Q=Q)\n",
    "      return sig.filtfilt(b, a, data, axis=0)\n",
    "\n",
    "  def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "      \"\"\"Apply a Butterworth bandpass filter.\"\"\"\n",
    "      nyq = 0.5 * fs\n",
    "      low = lowcut / nyq\n",
    "      high = highcut / nyq\n",
    "      b, a = sig.butter(order, [low, high], btype='band')\n",
    "      return sig.filtfilt(b, a, data, axis=0)\n",
    "\n",
    "    # Apply notch filters at 60 Hz harmonics (up to 300 Hz)\n",
    "  filtered = raw_eeg.copy()\n",
    "  for freq in [60, 120, 180, 240, 300]:\n",
    "      filtered = notch_filter(filtered, freq, fs)\n",
    "\n",
    "    # Apply bandpass filter (default 1â€“200 Hz)\n",
    "  clean_data = bandpass_filter(filtered, lowcut=1, highcut=200, fs=fs)\n",
    "\n",
    "  return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75c8f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(ecog_data, glove_data, win_len=256, step=128, delay=2):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(ecog_data) - win_len - delay, step):\n",
    "        window = ecog_data[i:i+win_len]\n",
    "        label = glove_data[i+delay:i+delay+win_len]\n",
    "        X.append(window)\n",
    "        Y.append(label)\n",
    "    return np.stack(X), np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c64f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerFlexDataset(Dataset):\n",
    "    def __init__(self, ecog, glove):\n",
    "        self.X = torch.tensor(ecog, dtype=torch.float32).permute(0, 2, 1)\n",
    "        self.Y = torch.tensor(glove, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75e74601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerFlexModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels=5):\n",
    "        super(FingerFlexModel, self).__init__()\n",
    "        \n",
    "        self.enc1 = self.block(input_channels, 32)\n",
    "        print(f\"enc1 initialized: input={input_channels}, output=32\")\n",
    "        \n",
    "        self.enc2 = self.block(32, 32)\n",
    "        print(f\"enc2 initialized: input=32, output=32\")\n",
    "        \n",
    "        self.enc3 = self.block(32, 64)\n",
    "        print(f\"enc3 initialized: input=32, output=64\")\n",
    "        \n",
    "        self.enc4 = self.block(64, 64)\n",
    "        print(f\"enc4 initialized: input=64, output=64\")\n",
    "        \n",
    "        self.enc5 = self.block(64, 128)\n",
    "        print(f\"enc5 initialized: input=64, output=128\")\n",
    "        \n",
    "        self.enc6 = self.block(128, 128)\n",
    "        print(f\"enc6 initialized: input=128, output=128\")\n",
    "        \n",
    "        self.dec1 = self.up(128, 128)\n",
    "        print(f\"dec1 initialized: input=128, output=128\")\n",
    "        \n",
    "        self.dec2 = self.up(256, 64)  # 128 + 128 = 256 input\n",
    "        print(f\"dec2 initialized: input=256, output=64\")\n",
    "        \n",
    "        self.dec3 = self.up(128, 64)  # 64 + 64 = 128 input\n",
    "        print(f\"dec3 initialized: input=128, output=64\")\n",
    "        \n",
    "        self.dec4 = self.up(128, 32)  # 64 + 64 = 128 i\n",
    "\n",
    "    def block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm(out_c),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f\"\\nForward pass:\")\n",
    "        print(f\"Input shape: {x.shape}\")  # [1, 62, 240000]\n",
    "        s = []\n",
    "        \n",
    "        # First encoder block\n",
    "        print(\"\\nEncoder Block 1:\")\n",
    "        x1 = self.enc1(x)\n",
    "        print(f\"After Conv1d: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After LayerNorm: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After GELU: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After Dropout: {x1.shape}\")  # [1, 32, 240000]\n",
    "        print(f\"After MaxPool: {x1.shape}\")  # [1, 32, 120000]\n",
    "        s.append(x1)\n",
    "        \n",
    "        # Second encoder block\n",
    "        print(\"\\nEncoder Block 2:\")\n",
    "        x2 = self.enc2(x1)\n",
    "        print(f\"After Conv1d: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After LayerNorm: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After GELU: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After Dropout: {x2.shape}\")  # [1, 32, 120000]\n",
    "        print(f\"After MaxPool: {x2.shape}\")  # [1, 32, 60000]\n",
    "        s.append(x2)\n",
    "        \n",
    "        # Continue with other blocks...\n",
    "        x3 = self.enc3(x2); s.append(x3)\n",
    "        x4 = self.enc4(x3); s.append(x4)\n",
    "        x5 = self.enc5(x4); s.append(x5)\n",
    "        x6 = self.enc6(x5)\n",
    "        \n",
    "        # Decoder blocks\n",
    "        d1 = self.dec1(x6)\n",
    "        d2 = self.dec2(torch.cat([d1, s[4]], dim=1))\n",
    "        d3 = self.dec3(torch.cat([d2, s[3]], dim=1))\n",
    "        d4 = self.dec4(torch.cat([d3, s[2]], dim=1))\n",
    "        d5 = self.dec5(torch.cat([d4, s[1]], dim=1))\n",
    "        \n",
    "        out = self.final(torch.cat([d5, s[0]], dim=1))\n",
    "        return out.permute(0, 2, 1)\n",
    "    \n",
    "    # def block(self, in_c, out_c):\n",
    "    #     return nn.Sequential(\n",
    "    #         nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
    "    #         nn.LayerNorm(out_c),\n",
    "    #         nn.GELU(),\n",
    "    #         nn.Dropout(0.1),\n",
    "    #         nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "    #     )\n",
    "    \n",
    "    def up(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        )\n",
    "    # def forward(self, x):\n",
    "    #     print(f\"\\nInput shape: {x.shape}\")\n",
    "    #     s = []\n",
    "        \n",
    "    #     x1 = self.enc1(x); s.append(x1)\n",
    "    #     print(f\"After enc1: {x1.shape}\")\n",
    "        \n",
    "    #     x2 = self.enc2(x1); s.append(x2)\n",
    "    #     print(f\"After enc2: {x2.shape}\")\n",
    "        \n",
    "    #     x3 = self.enc3(x2); s.append(x3)\n",
    "    #     print(f\"After enc3: {x3.shape}\")\n",
    "        \n",
    "    #     x4 = self.enc4(x3); s.append(x4)\n",
    "    #     print(f\"After enc4: {x4.shape}\")\n",
    "        \n",
    "    #     x5 = self.enc5(x4); s.append(x5)\n",
    "    #     print(f\"After enc5: {x5.shape}\")\n",
    "        \n",
    "    #     x6 = self.enc6(x5)\n",
    "    #     print(f\"After enc6: {x6.shape}\")\n",
    "        \n",
    "    #     d1 = self.dec1(x6)\n",
    "    #     print(f\"After dec1: {d1.shape}\")\n",
    "        \n",
    "    #     d2 = self.dec2(torch.cat([d1, s[4]], dim=1))\n",
    "    #     print(f\"After dec2: {d2.shape}\")\n",
    "        \n",
    "    #     d3 = self.dec3(torch.cat([d2, s[3]], dim=1))\n",
    "    #     print(f\"After dec3: {d3.shape}\")\n",
    "        \n",
    "    #     d4 = self.dec4(torch.cat([d3, s[2]], dim=1))\n",
    "    #     print(f\"After dec4: {d4.shape}\")\n",
    "        \n",
    "    #     d5 = self.dec5(torch.cat([d4, s[1]], dim=1))\n",
    "    #     print(f\"After dec5: {d5.shape}\")\n",
    "        \n",
    "    #     out = self.final(torch.cat([d5, s[0]], dim=1))\n",
    "    #     print(f\"After final: {out.shape}\")\n",
    "        \n",
    "    #     return out.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "436a1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, dilation=1, p_conv_drop=0.1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, \n",
    "                               kernel_size=kernel_size, \n",
    "                               bias=False, \n",
    "                               padding='same')\n",
    "        \n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "        self.drop = nn.Dropout(p=p_conv_drop)\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=stride, stride=stride)\n",
    "\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        \n",
    "        # norm by last axis\n",
    "        x = torch.transpose(x, -2, -1) \n",
    "        x = self.norm(x)\n",
    "        x = torch.transpose(x, -2, -1)\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, scale, **args):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "        self.conv_block = ConvBlock(**args)\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode='linear', align_corners=False)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.upsample(x)\n",
    "        return x    \n",
    "\n",
    "class AutoEncoder1D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_electrodes=62,   # Number of channels (ECoG electrodes)\n",
    "                 n_freqs=1,         # Number of frequency bands (1 for raw data)\n",
    "                 n_channels_out=5,  # Number of fingers to predict\n",
    "                 channels=[32, 64, 128, 128],  # Number of features on each encoder layer\n",
    "                 kernel_sizes=[3, 3, 3],\n",
    "                 strides=[2, 2, 2],  # Reduced stride to handle long sequences\n",
    "                 dilation=[1, 1, 1]\n",
    "                 ):\n",
    "        \n",
    "        super(AutoEncoder1D, self).__init__()\n",
    "        \n",
    "        self.n_electrodes = n_electrodes\n",
    "        self.n_freqs = n_freqs\n",
    "        self.n_inp_features = n_freqs * n_electrodes\n",
    "        self.n_channels_out = n_channels_out\n",
    "        \n",
    "        self.model_depth = len(channels)-1\n",
    "        \n",
    "        # Initial dimensionality reduction\n",
    "        self.spatial_reduce = ConvBlock(self.n_inp_features, channels[0], kernel_size=3)\n",
    "        \n",
    "        # Encoder part\n",
    "        self.downsample_blocks = nn.ModuleList([\n",
    "            ConvBlock(channels[i], channels[i+1], \n",
    "                     kernel_sizes[i],\n",
    "                     stride=strides[i], \n",
    "                     dilation=dilation[i]) \n",
    "            for i in range(self.model_depth)\n",
    "        ])\n",
    "\n",
    "        # Prepare channels for decoder\n",
    "        channels = [ch for ch in channels[:-1]] + channels[-1:]\n",
    "\n",
    "        # Decoder part with skip connections\n",
    "        self.upsample_blocks = nn.ModuleList([\n",
    "            UpConvBlock(scale=strides[i],\n",
    "                       in_channels=channels[i+1] if i == self.model_depth-1 else channels[i+1]*2,\n",
    "                       out_channels=channels[i],\n",
    "                       kernel_size=kernel_sizes[i]) \n",
    "            for i in range(self.model_depth-1, -1, -1)\n",
    "        ])\n",
    "        \n",
    "        # Final 1x1 convolution\n",
    "        self.conv1x1_one = nn.Conv1d(channels[0]*2, self.n_channels_out, kernel_size=1, padding='same')\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch, electrodes, time]\n",
    "        batch, elec, time = x.shape\n",
    "        \n",
    "        # Add frequency dimension if needed\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(2)  # [batch, electrodes, 1, time]\n",
    "            \n",
    "        # Reshape and process\n",
    "        x = x.reshape(batch, -1, time)  # flatten the input\n",
    "        x = self.spatial_reduce(x)\n",
    "        \n",
    "        # Encoder path with skip connections\n",
    "        skip_connections = []\n",
    "        for i in range(self.model_depth):\n",
    "            skip_connections.append(x)\n",
    "            x = self.downsample_blocks[i](x)\n",
    "\n",
    "        # Decoder path with skip connections\n",
    "        for i in range(self.model_depth):\n",
    "            x = self.upsample_blocks[i](x)\n",
    "            x = torch.cat((x, skip_connections[-1 - i]), dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        x = self.conv1x1_one(x)\n",
    "        return x.permute(0, 2, 1)  # [batch, time, fingers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ea88c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    def forward(self, pred, target):\n",
    "        mse = self.mse(pred, target)\n",
    "        cos = F.cosine_similarity(pred, target, dim=-1).mean()\n",
    "        return 0.5 * (mse + (1 - cos))\n",
    "\n",
    "def train_model(model, train_loader, epochs=10, lr=8.4e-5):\n",
    "    model.train()\n",
    "    loss_fn = CombinedLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba0475f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'raw_training_data.mat' # file path\n",
    "test_file = 'leaderboard_data.mat'\n",
    "\n",
    "# load training data\n",
    "train_data = sio.loadmat(train_file) # returns dict with keys and values as numpy arrays\n",
    "ecog = train_data['train_ecog']\n",
    "data_glove = train_data['train_dg']\n",
    "\n",
    "# leaderboard testing data\n",
    "test_data = sio.loadmat(test_file)\n",
    "leaderboard_ecog = test_data['leaderboard_ecog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08e5cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ecog = []\n",
    "test_ecog = []\n",
    "train_glove = []\n",
    "test_glove = []\n",
    "\n",
    "train_len = int(0.8*len(ecog[0][0]))\n",
    "\n",
    "for subject_idx in range(3):\n",
    "    ecog_data = ecog[subject_idx]\n",
    "    glove_data = data_glove[subject_idx]\n",
    "    train_ecog.append(ecog_data[0][:train_len])\n",
    "    test_ecog.append(ecog_data[0][train_len:])\n",
    "    train_glove.append(glove_data[0][:train_len])\n",
    "    test_glove.append(glove_data[0][train_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7178e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1000\n",
    "xLen = len(train_ecog[0])\n",
    "winLen= 0.1\n",
    "winDisp = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82755ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumWins(xLen, fs, winLen, winDisp):\n",
    "  winLen = winLen * fs\n",
    "  winDisp = winDisp * fs\n",
    "  return int((xLen - winLen) // winDisp + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b56a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4799"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumWins(xLen, fs, winLen, winDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a498a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ecogs = [filter_data(ecog) for ecog in train_ecog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c140f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize glove\n",
    "normalized_gloves = [(train_glove_i - train_glove_i.min()) / (train_glove_i.max() - train_glove_i.min()) for train_glove_i in train_glove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24927db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_windows(filtered_ecogs[0], normalized_gloves[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cac2c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "dataset = FingerFlexDataset(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb3d4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4f94b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15c26c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered ECoG tensor shape: torch.Size([1, 62, 240000])\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the array to ensure positive strides\n",
    "filtered_ecog_tensor = torch.from_numpy(filtered_ecogs[0].copy()).float()\n",
    "\n",
    "# Now you can safely transpose and add batch dimension\n",
    "if len(filtered_ecog_tensor.shape) == 2:  # If it's (time_steps, channels)\n",
    "    filtered_ecog_tensor = filtered_ecog_tensor.T  # Transpose to (channels, time_steps)\n",
    "    filtered_ecog_tensor = filtered_ecog_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Filtered ECoG tensor shape:\", filtered_ecog_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2edb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Filtered ECoG tensor shape: torch.Size([1, 240000, 62])\n"
     ]
    }
   ],
   "source": [
    "# Current shape: [1, 240000, 62]\n",
    "# We want: [1, 62, 240000]\n",
    "\n",
    "# First, remove the batch dimension\n",
    "filtered_ecog_tensor = filtered_ecog_tensor.squeeze(0)  # Now [240000, 62]\n",
    "\n",
    "# Then transpose to get channels first\n",
    "filtered_ecog_tensor = filtered_ecog_tensor.T  # Now [62, 240000]\n",
    "\n",
    "# Finally, add batch dimension back\n",
    "filtered_ecog_tensor = filtered_ecog_tensor.unsqueeze(0)  # Now [1, 62, 240000]\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Corrected Filtered ECoG tensor shape:\", filtered_ecog_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52f029ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder1D(\n",
       "  (spatial_reduce): ConvBlock(\n",
       "    (conv1d): Conv1d(62, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (downsample_blocks): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (downsample): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1d): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (downsample): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (downsample): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (upsample_blocks): ModuleList(\n",
       "    (0): UpConvBlock(\n",
       "      (conv_block): ConvBlock(\n",
       "        (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "    )\n",
       "    (1): UpConvBlock(\n",
       "      (conv_block): ConvBlock(\n",
       "        (conv1d): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "    )\n",
       "    (2): UpConvBlock(\n",
       "      (conv_block): ConvBlock(\n",
       "        (conv1d): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "    )\n",
       "  )\n",
       "  (conv1x1_one): Conv1d(64, 5, kernel_size=(1,), stride=(1,), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb3730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1854\n"
     ]
    }
   ],
   "source": [
    "train_model(model, loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55384ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input shape: torch.Size([1, 62, 240000])\n",
      "enc1 initialized: input=62, output=32\n",
      "enc2 initialized: input=32, output=32\n",
      "enc3 initialized: input=32, output=64\n",
      "enc4 initialized: input=64, output=64\n",
      "enc5 initialized: input=64, output=128\n",
      "enc6 initialized: input=128, output=128\n",
      "dec1 initialized: input=128, output=128\n",
      "dec2 initialized: input=256, output=64\n",
      "dec3 initialized: input=128, output=64\n",
      "\n",
      "Forward pass:\n",
      "Input shape: torch.Size([1, 62, 240000])\n",
      "\n",
      "Encoder Block 1:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[32], expected input with shape [*, 32], but got input of size[1, 32, 240000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create and test the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m FingerFlexModel(input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m62\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[103], line 50\u001b[0m, in \u001b[0;36mFingerFlexModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# First encoder block\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEncoder Block 1:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter Conv1d: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# [1, 32, 240000]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter LayerNorm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# [1, 32, 240000]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/functional.py:2910\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2902\u001b[0m         layer_norm,\n\u001b[1;32m   2903\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2908\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2909\u001b[0m     )\n\u001b[0;32m-> 2910\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[32], expected input with shape [*, 32], but got input of size[1, 32, 240000]"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor\n",
    "sample_input = torch.randn(1, 62, 240000)  # (batch_size, channels, time_steps)\n",
    "print(\"Sample input shape:\", sample_input.shape)\n",
    "\n",
    "# Create and test the model\n",
    "model = FingerFlexModel(input_channels=62)\n",
    "output = model(sample_input)\n",
    "print(\"\\nFinal output shape:\", output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
